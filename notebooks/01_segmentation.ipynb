{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba80f905-68c8-478a-a53b-69971c4793a7",
   "metadata": {},
   "source": [
    "# Fastai Segmentation (Using 1024 res images)\n",
    "This notebook features an example of training a segmentation model on the photos of the chest X-ray images. Segmentation model can then be used for pacemaker localization an subsequent classification, as shown in the other notebooks. As inputs, the model uses smartphone camera photos of the X-ray images. To provide ground truth segmentation maks, the photos were manually annotated. \n",
    "\n",
    "During preprocessing, image is first rescaled preserving aspect ratio to be 1024 in the smallest dimension, center-cropped to fit a square. During training, a random square patch of size 256 is taken, data augmentations are then applied.\n",
    "For visualization, dataloader is initialized again with the different transform -  in this case, after resizing to size 1024, no further transforms are applied, so that the whole center 1024x1024 square is segmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5937f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import PIL.Image\n",
    "from PIL import ImageOps\n",
    "import skimage\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101602e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to standardize the square crops\n",
    "def resize_img(img, small_ax=1024):\n",
    "    scale_f = 1024 / min(img.size)\n",
    "    return img.resize((np.floor(img.size[0] * scale_f).astype(int), np.floor(img.size[1] * scale_f).astype(int)))\n",
    "\n",
    "\n",
    "def center_crop(img, ax=1024):\n",
    "    img = resize_img(img, ax)\n",
    "    width, height = img.size  # Get dimensions\n",
    "\n",
    "    left = (width - ax) / 2\n",
    "    top = (height - ax) / 2\n",
    "    right = (width + ax) / 2\n",
    "    bottom = (height + ax) / 2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    return img\n",
    "\n",
    "\n",
    "def fix_bbox(bbox_org, img_shape, minsize=160, verbose=False):\n",
    "    \"\"\"\n",
    "    This function is used to standardize the square crops obtained using the semgentation model\n",
    "    for classification.\n",
    "    \"\"\"\n",
    "    # Add margins to the detected object crop\n",
    "    minr, minc, maxr, maxc = bbox_org\n",
    "    minr -= int(np.floor((maxr - minr) * 0.2))\n",
    "    minc -= int(np.floor((maxc - minc) * 0.2))\n",
    "    maxr += int(np.floor((maxr - minr) * 0.2))\n",
    "    maxc += int(np.floor((maxc - minc) * 0.2))\n",
    "\n",
    "    # Set the minimal size to the object crop\n",
    "    dr = max(0, minsize - (maxr - minr))\n",
    "    dc = max(0, minsize - (maxc - minc))\n",
    "    minr -= dr // 2\n",
    "    maxr += dr // 2\n",
    "    minc -= dc // 2\n",
    "    maxc += dc // 2\n",
    "\n",
    "    # Make crop a square\n",
    "    hr = maxr - minr\n",
    "    hc = maxc - minc\n",
    "    maxh = max(hr, hc)\n",
    "    dr = maxh - hr\n",
    "    dc = maxh - hc\n",
    "    minr -= dr // 2\n",
    "    maxr += dr // 2\n",
    "    minc -= dc // 2\n",
    "    maxc += dc // 2\n",
    "\n",
    "    # Shift the expanded crop so it located within the image\n",
    "    if verbose:\n",
    "        print(img_shape)\n",
    "        print(minr, maxr, minc, maxc)\n",
    "    drmin = min(0, img_shape[0] - maxr)\n",
    "    minr += drmin\n",
    "    maxr = min(img_shape[0], maxr)\n",
    "\n",
    "    drmax = min(0, minr)\n",
    "    maxr -= drmax\n",
    "    minr = max(0, minr)\n",
    "\n",
    "    dcmin = min(0, img_shape[1] - maxc)\n",
    "    minc += dcmin\n",
    "    maxc = min(img_shape[1], maxc)\n",
    "\n",
    "    dcmax = min(0, minc)\n",
    "    maxc -= dcmax\n",
    "    minc = max(0, minc)\n",
    "    if verbose:\n",
    "        print(minr, maxr, minc, maxc)\n",
    "\n",
    "    return minr, minc, maxr, maxc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122e545",
   "metadata": {},
   "source": [
    "Setting the paths to the `Dataset` folder containing the images. Relative path is defined in order to update the metadata dataframe used to initialize the dataloader, since `ImageDataLoaders.from_df` strictly uses relative pathing for the label column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14cdccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_dataset_path = Path(\"/workdir/cied/Dataset\")\n",
    "rel_dataset_path = Path(os.path.relpath(abs_dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4006ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the metadata spreadsheet\n",
    "df = pd.read_excel(abs_dataset_path / \"dataset_annotations_exper.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8feb8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the relative file paths to the data filenames\n",
    "df.loc[:, \"segmentation_x\"] = df.loc[:, \"segmentation_x\"].apply(lambda x: str(rel_dataset_path / x))\n",
    "df.loc[:, \"segmentation_y\"] = df.loc[:, \"segmentation_y\"].apply(lambda x: str(rel_dataset_path / x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef54b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monitor      1250\n",
       "pacemaker    1231\n",
       "Name: annotation, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing the class distribution between pacemakers and monitors in the training set by duplicating monitor entries\n",
    "df_mon = df[(df[\"is_valid\"] == False) & (df[\"annotation\"] == \"monitor\")]\n",
    "resampled_df = pd.concat([df] + [df_mon] * 6).reset_index()\n",
    "resampled_df[\"annotation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a679c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the experiment name to save the model\n",
    "exp_name = \"s1024_sc_resnet50_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed878f0-1324-465f-b974-a269b0cd7bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing the fastai dataloader\n",
    "dls = ImageDataLoaders.from_df(\n",
    "    resampled_df,\n",
    "    fn_col=\"segmentation_x\",\n",
    "    label_col=\"segmentation_y\",\n",
    "    valid_col=\"is_valid\",\n",
    "    item_tfms=Resize(1024),\n",
    "    batch_tfms=[*aug_transforms(size=256, min_scale=0.1)],\n",
    "    y_block=MaskBlock(),\n",
    "    bs=48,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e03e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seeds for reproducibility purposes\n",
    "set_seed(42, True)\n",
    "dls.rng.seed(42)\n",
    "# Initializing the learner\n",
    "learner = unet_learner(dls, resnet50, n_out=3, pretrained=True, metrics=DiceMulti).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a68c0b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.402735</td>\n",
       "      <td>0.092950</td>\n",
       "      <td>0.491232</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.179505</td>\n",
       "      <td>0.032976</td>\n",
       "      <td>0.910383</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.086068</td>\n",
       "      <td>0.021890</td>\n",
       "      <td>0.941754</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047675</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>0.947781</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>0.019442</td>\n",
       "      <td>0.947509</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.022277</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.948929</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>0.019731</td>\n",
       "      <td>0.945710</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.016679</td>\n",
       "      <td>0.954505</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020790</td>\n",
       "      <td>0.027913</td>\n",
       "      <td>0.925137</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.018624</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.956622</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.963635</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>0.961790</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018986</td>\n",
       "      <td>0.020941</td>\n",
       "      <td>0.946434</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.965685</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014968</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>0.969690</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>0.969166</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.013068</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>0.972796</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.972673</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.972053</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.971716</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.971732</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.975020</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.973930</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>0.974773</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0.976579</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.974828</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.975670</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.976904</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.007897</td>\n",
       "      <td>0.976890</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.976920</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.977196</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.977138</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>0.977072</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model training\n",
    "# Training the head\n",
    "learner.fit_one_cycle(5, 3e-3)\n",
    "# Training the whole network\n",
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(30, lr_max=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40785b",
   "metadata": {},
   "source": [
    "The algorithm has achieved a Dice score of 0.970 on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effcbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "save_model(\"models/{}\".format(exp_name), learner.model, learner.opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e4b81",
   "metadata": {},
   "source": [
    "## Generating object crops for the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a456aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "dls = ImageDataLoaders.from_df(\n",
    "    resampled_df.iloc[:10],\n",
    "    fn_col=\"segmentation_x\",\n",
    "    label_col=\"segmentation_y\",\n",
    "    valid_col=\"is_valid\",\n",
    "    y_block=MaskBlock(),\n",
    "    bs=1,\n",
    ")\n",
    "\n",
    "learner = unet_learner(dls, resnet50, n_out=3, pretrained=True, metrics=DiceMulti).to_fp16()\n",
    "# load_model(\"models/{}\".format(exp_name), learner.model, learner.opt, device=\"cuda:0\")\n",
    "load_model(\"models/{}\".format(exp_name), learner.model, learner.opt, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting crop parameters - minimal crop size and maxima\n",
    "minsize = 160\n",
    "final_size = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69beaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_excel(abs_dataset_path / \"dataset_clf.xlsx\")\n",
    "new_df.set_index(new_df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting input and output directories\n",
    "input_dir = abs_dataset_path / \"Handyfotos\"\n",
    "output_dir = abs_dataset_path / \"Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb33c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(new_df)):\n",
    "    row = new_df.iloc[i]\n",
    "    img_path = input_dir / row[\"dataset\"] / row[\"filename\"]\n",
    "    img = PIL.Image.open(img_path)\n",
    "    img = ImageOps.exif_transpose(img)\n",
    "    img = np.array(resize_img(img))\n",
    "\n",
    "    # Predicting the segmentation mask\n",
    "    res = learner.predict(img, with_input=True)\n",
    "\n",
    "    mask = np.array(res[1])\n",
    "    mask[mask != 1] = 0\n",
    "\n",
    "    # Finding the largest connected component\n",
    "    labeled_image, count = skimage.measure.label(mask, return_num=True)\n",
    "    objects = skimage.measure.regionprops(labeled_image)\n",
    "    if len(objects) == 0:\n",
    "        continue\n",
    "    object_areas = [obj[\"area\"] for obj in objects]\n",
    "    max_idx = np.argmax(object_areas)\n",
    "    obj = objects[max_idx]\n",
    "\n",
    "    # Defining the crop\n",
    "    minr, minc, maxr, maxc = fix_bbox(obj[\"bbox\"], img.shape)\n",
    "    crop = img[minr:maxr, minc:maxc]\n",
    "\n",
    "    # Cropping, resizing and saving\n",
    "    crop = PIL.Image.fromarray(crop).resize(final_size)\n",
    "    crop.save(output_dir / row[\"patch_fname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the datasets for classification\n",
    "\n",
    "result_fnames = os.listdir(output_dir)\n",
    "\n",
    "flag = ~new_df[\"patch_fname\"].apply(lambda x: x in result_fnames)\n",
    "\n",
    "missing_df = new_df[flag]\n",
    "missing_df.index.name = \"dicom_path\"\n",
    "\n",
    "seg_df = new_df[~flag]\n",
    "seg_df.index.name = \"dicom_path\"\n",
    "\n",
    "missing_df.to_excel(abs_dataset_path / \"failed_segmentations.xlsx\")\n",
    "seg_df.to_excel(abs_dataset_path / \"dataset_clf_seg.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
